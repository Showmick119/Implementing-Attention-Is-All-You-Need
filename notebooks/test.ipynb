{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Testing the Transformer Model\n",
        "\n",
        "This notebook demonstrates how to load a trained Transformer model and use it for sequence generation. We'll use the model we trained in the `train.ipynb` notebook.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's install the required packages and import dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch numpy matplotlib\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "notebook_path = Path.cwd()\n",
        "project_root = notebook_path.parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from transformer.config import TransformerConfig\n",
        "from transformer.model import Transformer\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Load Model\n",
        "\n",
        "Let's load the trained model from the checkpoint file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint_path = project_root / 'checkpoints' / 'transformer_model.pt'\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "# Create model configuration\n",
        "config = TransformerConfig(**checkpoint['config'])\n",
        "\n",
        "# Create and load model\n",
        "model = Transformer(config).to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"\\nModel configuration:\")\n",
        "for key, value in config.__dict__.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Generate Sequences\n",
        "\n",
        "Now we'll use the model to generate sequences. For this demonstration, we'll use random input sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create random input sequence\n",
        "batch_size = 3\n",
        "src = torch.randint(4, config.vocab_size, (batch_size, config.max_seq_len), device=device)\n",
        "\n",
        "# Generate sequences\n",
        "with torch.no_grad():\n",
        "    output_sequences, attention_weights = model.generate(\n",
        "        src,\n",
        "        max_length=config.max_seq_len,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "print(\"Input sequences:\")\n",
        "print(src)\n",
        "print(\"\\nGenerated sequences:\")\n",
        "print(output_sequences)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Visualize Attention\n",
        "\n",
        "Let's visualize the attention patterns from the model. We'll look at both encoder self-attention and decoder cross-attention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_attention(attention_weights, title):\n",
        "    \"\"\"Plot attention weights as a heatmap.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        attention_weights.cpu().numpy(),\n",
        "        cmap='viridis',\n",
        "        xticklabels=range(attention_weights.size(-1)),\n",
        "        yticklabels=range(attention_weights.size(-2))\n",
        "    )\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Key position')\n",
        "    plt.ylabel('Query position')\n",
        "    plt.show()\n",
        "\n",
        "# Plot encoder self-attention (first layer, first head, first batch)\n",
        "encoder_attention = attention_weights['encoder_attention'][0, 0, 0]\n",
        "plot_attention(encoder_attention, 'Encoder Self-Attention (Layer 0, Head 0)')\n",
        "\n",
        "# Plot decoder cross-attention (first layer, first head, first batch)\n",
        "decoder_cross_attention = attention_weights['decoder_cross_attention'][0, 0, 0]\n",
        "plot_attention(decoder_cross_attention, 'Decoder Cross-Attention (Layer 0, Head 0)')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "To use this model for real translation tasks:\n",
        "\n",
        "1. Replace the toy dataset with a real parallel corpus\n",
        "2. Implement proper tokenization using SentencePiece or a similar tokenizer\n",
        "3. Add evaluation metrics like BLEU score\n",
        "4. Train for more epochs on more data\n",
        "5. Use larger model dimensions as specified in the paper\n",
        "\n",
        "The current implementation demonstrates the core Transformer architecture and can be extended for various sequence-to-sequence tasks.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
